---
title     : "Assignment 3 - Solution"
subtitle  : ""
author    : "Nicole Cruz & Julia Haaf"
date      : ""

header-includes:
   - \usepackage{enumitem}
   - \usepackage{amsmath}
   - \usepackage{setspace}
   - \usepackage{bm}

output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
params <- list(solution = T)
```

## Preparation

```{r message = FALSE}
# packages
library("brms")
library("ggplot2")
library("tidyverse")

# data
load("data/income.RData")
```

**data**: `income.RData`

```{r}
head(income)
```

The data set contains four variables

| Variable     | Description                     |
|--------------|---------------------------------|
| `ls`         | Life satisfaction (1-5)        |
| `emotst`     | Emotional stability (1-7)      |
| `emotst_cat` | Emot. stability (high-low) |
| `inc_hh`     | Household income (in 10.000)  |


## Excercise 1

Fit the following Bayesian model to assess the effect of household income on life satisfaction.

```{r}
# Casewise exclusion of missing data
income <- na.exclude(income)

# This function can be used to figure out the structure of the priors for the sepcific model including names of the predictors
# default_prior(ls ~ inc_hh,
#              data = income)

bprior <- c(brms::prior(normal(3, 2), class = Intercept)
            , brms::prior(normal(0, 1), class = b, coef = inc_hh)
            , brms::prior(normal(0, 2.5), class = sigma))
```

```{r modelest, cache = T, warning=T, message=T}
model.1 <- brm(ls ~ 1 + inc_hh
               , data = income
               , prior = bprior
               , silent = 2
               , refresh = 0)
```

a) Consider the priors. Do you think they are a good choice? What would you change (if anything).

b) Ensure convergence and visuaalize the posterior distributions of all parameters. Interpret the results.

```{r eval = !params$solution, echo = F}
knitr::asis_output("<!--")
```

#### Solution


- $Y_i:$ Life satisfaction of the $i$th person
- $x_{i}:$ Income


$$Y_i \sim \mbox{Normal}(\mu_i, \sigma^2)$$
$$\mu_i = \beta_0 + x_{i}\beta_1$$


1a. The `ls`-values are between 1 and 5, so effects cannot be larger than one step on the life satisfaction scale. The mean is probably around 3. Sigma, the noise standard deviation can also not be bigger than 2-3 because of the range restriction of the data.

1b. 

```{r eval = params$solution, echo = params$solution}
plot(model.1)
```

None of the posterior credible intervals includes 0. For an increase of  10.000 Euros of household income there is an increase of life satsifaction of about 0.07 points.

```{r eval = params$solution, echo = params$solution}
## Neue Daten werden erstellt, um die Regressionsgerade zu zeichnen
nd <- tibble(inc_hh = -1:13, 2)
## Regression wird auf die neuen Daten angewendet
f <- fitted(model.1, newdata = nd) %>% 
  as_tibble() %>%
  bind_cols(nd)
income %>%
  ggplot(aes(x = inc_hh)) +
  geom_smooth(data = f,
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity", 
              alpha = 1/4, linewidth = 1/2) +
  geom_point(aes(y = ls),
             size = 2/3) +
  scale_x_continuous("Income", expand = c(0, 0)) +
  ylab("Life satisfaction") + 
  theme_light(base_size = 20, )
```

```{r eval = !params$solution, echo = F}
knitr::asis_output("-->")
```

c) Is there evidence that household income influences life satisfaction? Compare Model 1 to an alternative model without the income effect using Bayes factor.

d) Also compare the posterior prediction of the models. Is one of them better than the other?


```{r eval = !params$solution, echo = F}
knitr::asis_output("<!--")
```

#### Solution

1c.

```{r modelest2, cache = T, warning=T, message=T}
bprior <- c(brms::prior(normal(3, 2), class = Intercept)
            , brms::prior(normal(0, 2.5), class = sigma))

model.0 <- brm(ls ~ 1
               , data = income
               , prior = bprior
               , silent = 2)

bayes_factor(model.1, model.0)
```

1d.

```{r eval = params$solution, echo = params$solution}
post.pred.1 <- posterior_predict(model.1)
post.pred.0 <- posterior_predict(model.0)
```

```{r eval = params$solution, echo = params$solution}
par(mar = c(4,4,.5,.5), cex = 1.3, mgp = c(2, .7, 0))
post.pred.mean.1 <- colMeans(post.pred.1)
plot(post.pred.mean.1
     , income$ls
     , ylab = "Data", xlab = "Predicted"
     , pch = 1, col = "darkgray"
     , ylim = c(.5, 5.5), xlim = c(.5, 5.5))
abline(0, 1, lwd = 2)
cor(post.pred.mean.1, income$ls)
```

```{r eval = params$solution, echo = params$solution}
par(mar = c(4,4,.5,.5), cex = 1.3, mgp = c(2, .7, 0))
post.pred.mean.0 <- colMeans(post.pred.0)
plot(post.pred.mean.0
     , income$ls
     , ylab = "Data", xlab = "Predicted"
     , pch = 1, col = "darkgray"
     , ylim = c(.5, 5.5), xlim = c(.5, 5.5))
abline(0, 1, lwd = 2)
cor(post.pred.mean.0, income$ls)
```

```{r eval = !params$solution, echo = F}
knitr::asis_output("-->")
```

